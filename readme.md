## Демонстрационный пайплайн

#### Done
- API с возможностью загрузки данных из CSV в Postgres.
- ML модель с использованием TensorFlow
- Обучение модели в Airflow с сохранением в S3 Minio. Модель обучается на CPU.
- Predict с выгрузкой модели из S3 и сохранением результатов в БД с последующей возможностью выгрузки результатов в CSV.
- docker-compose для запуска всех сервисов на базе штатного от Airflow.

#### TODO
- Разделить train на стадии: получение данных >> обработка >> обучение и сохранение
- Выбор версии для предсказаний
- Модели данных для sqlalchemy
- Корректная обработка ошибок

#### Первый запуск
Необходимо инициализировать базу данных для Airflow
```shell
docker-compose up airflow-init
```

#### Запустить сервисы
```shell
docker-compose up
```

#### Загрузить данные train + predict в API
Старые данные стираются при каждой загрузке

<http://0.0.0.0:8081/>


#### Запустить train модели в Airflow
Данные загружаются из БД
Login `airflow`
Password `airflow`

<http://0.0.0.0:8080/>


#### Модель будет сохранена в Minio
Login `minio`
Password `miniopass`

<http://0.0.0.0:9001/>


#### Predict
После можно запустить predict через API и скачать результаты. Из Minio будет выгружена последняя загруженная модель, 
данные будут сохранены в БД, могут быть выгружены в CSV через API